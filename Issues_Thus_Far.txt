Goals for tomarrow:
set up base agent class X
set up tit for tat, evil, and good agents X

set up basic implementation for main class X
Add game class X
Add visualization
- I want it to show the strategy, each win, and update the score.
so far I show the strategy and update the score
I want to make the memory work for tit-for-tat, its due to it not remembering 'faces', but just having a general memory of neighbors
    add decorators
    add time checking
    add circles

Creating a hash system for memory, check notebook for more. X
The algorithm:
Hash table. I can abuse the fact that I only have 4 output states, and 4 combinations of inputs.
hash algorithm:
    factors: round, agent1, and agent2
    I dedicate 16 bits for round, and 8 each for agent 1 and agent 2, and then bitshift the round 16 to the left and agent 1 to the right, before merging the bitspaces together.
    I also cut memory in half by always having player 1 be the agent with the lower ID, meaning I can infer agent without needing iti stored.
    This has given some really nice results, with processing speeds for gameplay being fast enough to not bottleneck the system.


Time examples:

10x10 grid, 1,000 iterations

    Creating agents...
    Done. Time elapsed: 0.0 seconds.
    Creating world...
    Done. Time elapsed: 0.006682872772216797 seconds.
    Updating neighbors...
    Done. Time elapsed: 0.000997781753540039 seconds.
    Starting game...
    Done. Time elapsed: 0.0 seconds.
    Playing game...
    Done. Time elapsed: 7.4314587116241455 seconds.
    Each round took 0.007431458711624145 seconds.
    Printing scores in a grid for human readability...
    7000    13000   13000   9000    13000   6000    12000   12000   15000   9000
    17000   12000   12000   20000   24000   9000    32000   12000   15000   9000
    9000    18000   15000   12000   24000   9000    24000   24000   28000   21000
    9000    36000   18000   32000   12000   24000   6000    16000   6000    6000
    13000   12000   12000   15000   28000   15000   28000   28000   32000   12000
    17000   32000   18000   36000   15000   15000   12000   9000    12000   9000
    6000    15000   18000   21000   18000   40000   15000   32000   32000   12000
    25000   18000   21000   18000   18000   18000   12000   24000   9000    9000
    12000   18000   40000   18000   40000   21000   15000   28000   28000   12000
    9000    12000   12000   9000    12000   12000   9000    17000   6000    6000
    Done. Time elapsed: 0.007860898971557617 seconds.

consider modifying the agents so that you don't have to enter both the strategy and movement strategy manually,
since there could be a lot of overlap, where you apply many strategies to the same movement strategy (I can probably just use subclass)

MAJOR UPDATE:
Agents are no longer grid based, and are now circles that move around the screen.
Instead of having a grid, I now have a list of agents.
Instead of having neighbors, I now have them check for collisions with other agents, and then play the game with them.

I used a a temporary file (pycirlces) to learn about how to make circles move around the screen, and then I used that knowledge to make this.

new list of todos:
Standardize docstrings
Standardize & add comments
Add more strategies
Add more movement strategies
add drift X
add momentum
Improve collision
Add testability, through decorators for printing and time checking
Add file output
add data analysis
add downloadability/portability
add command line args


New New list of todos:
1. Add Movement strategies
 - Chaser, takes the acceleration of their last collision
 - runner, takes the opposite of their last collision
 - random
 - dodger, takes the opposite of their last collision, but randomizes one of the axis
 - straight, always moves in the line it was moving in, still bounces off walls
2. Add data analysis
 - Add data to a file
 - create a program that can graph the data
3. Collision
 - start with grid based
 - add more from chatgpt if needed
 - add a little collision visual
 - prioritize quality
4. Move to another language
 - Ask about use of libraries
 - refer back to https://www.youtube.com/watch?v=lS_qeBy3aQI, pezzzas work
5. Hash function/ data structure
 - The current hash still works, however it can be made more space efficient
  - previous design: assigning bits for certain roles, specifically the round, agent1, and agent2. This made some blank space, but not much
  - maybe it can be improved?

This code produces an interesting mechanic where they occasionally merge together and collide frequently, which could be an interesting thing to explore.
for agent in self.agents:
            for agent2 in self.agents:
                if agent != agent2:
                    if (agent.get_position()[0] - agent2.get_position()[0])**2 + (agent.get_position()[1] - agent2.get_position()[1])**2 <= (self.agents_size*2)**2:
                        agent.set_position(agent.get_position()[0] - agent.get_direction()[0], agent.get_position()[1] - agent.get_direction()[1])
                        # agent2.set_position(agent2.get_position()[0] - agent2.get_direction()[0], agent2.get_position()[1] - agent2.get_direction()[1])
                        self.game.play(agent, agent2)
                        agent.set_direction([agent.get_direction()[0] * -1, agent.get_direction()[1] * -1])
                        # agent2.set_direction([agent2.get_direction()[0] * -1, agent2.get_direction()[1] * -1])
            if agent.get_position()[0] - self.agents_size <= 0 or agent.get_position()[0] + self.agents_size >= self.world_size:
                agent.set_position(agent.get_position()[0] - agent.get_direction()[0], agent.get_position()[1])
                # agent.set_direction([agent.get_direction()[0] * -1, agent.get_direction()[1]])
            if agent.get_position()[1] - self.agents_size <= 0 or agent.get_position()[1] + self.agents_size >= self.world_size:
                agent.set_position(agent.get_position()[0], agent.get_position()[1] - agent.get_direction()[1])
                # agent.set_direction([agent.get_direction()[0], agent.get_direction()[1] * -1])